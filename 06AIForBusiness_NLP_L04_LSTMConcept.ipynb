{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqZie_gK9KJ0"
      },
      "source": [
        "# AI For Business\n",
        "## Module : Natural Language Processing - End to end Example\n",
        "\n",
        "### Lesson 04\n",
        "### Use Keras Based Network for understanding concepts in LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGiY9QO--eFK"
      },
      "source": [
        "## Key Steps and Learnings Expected\n",
        "1.   Setup and Data Acquisition\n",
        "2.   Load a Clean Dataset\n",
        "3.   Text Processing and Analysis (Sentences, Tokens and Stemming)\n",
        "4.   Text Representation - Encoding\n",
        "5.   Text Representation - Bag of words\n",
        "6.   Text Representation - Bag of N-Grams\n",
        "7.   Text Representation - TFIDF\n",
        "8.   Word Embeddings - Word2Vec, Glove.\n",
        "9.   Visualize Embeddings\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdPxCH79BTcF"
      },
      "source": [
        "### S1B : Load Libraries and Sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u-V3aWCGdpv0"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(100)\n",
        "\n",
        "data = ['xyzaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaxyz', 'pqraaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaapqr']\n",
        "\n",
        "test_data = ['xyzaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaxyz','pqraaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaapqr']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "metadata": {
        "id": "KJMsfqqfgPmw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the Data using Sklearn's LabelEncoder and OneHotEncoder (One-hot vectors for every character)\n",
        "enc = LabelEncoder()\n",
        "alphabet = np.array(list(set([c for w in data for c in w])))  #Unique set of characters\n",
        "enc.fit(alphabet)\n",
        "int_enc=enc.fit_transform(alphabet)\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "int_enc=int_enc.reshape(len(int_enc), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(int_enc)"
      ],
      "metadata": {
        "id": "7BQmgitQZYx3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet, int_enc  #Encoding : Integer Encoding example"
      ],
      "metadata": {
        "id": "1tmFDwgUZ7m4",
        "outputId": "b05017a2-46b4-4e6c-ad94-eaf36ded0cff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['r', 'x', 'a', 'q', 'z', 'p', 'y'], dtype='<U1'),\n",
              " array([[3],\n",
              "        [4],\n",
              "        [0],\n",
              "        [2],\n",
              "        [6],\n",
              "        [1],\n",
              "        [5]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded  #Encoding : Vector / Array or Binary"
      ],
      "metadata": {
        "id": "GswZJvHHZ4sh",
        "outputId": "660f1098-8057-4806-c655-fc558705725e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our Training Data\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "\n",
        "for w in data:\n",
        "    for i in range(len(w)-1):\n",
        "        X_train.extend(onehot_encoder.transform([enc.transform([w[i]])]))\n",
        "        y_train.extend(onehot_encoder.transform([enc.transform([w[i+1]])]))"
      ],
      "metadata": {
        "id": "V47x_nHqZV7O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our Test Data\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "\n",
        "for w in test_data:\n",
        "    for i in range(len(w)-1):\n",
        "        test_enc = onehot_encoder.transform([enc.transform([w[i]])])\n",
        "        X_test.extend(test_enc)\n",
        "        y_test.extend(onehot_encoder.transform([enc.transform([w[i+1]])]))\n",
        "\n",
        "len(X_test), X_test[0:10]"
      ],
      "metadata": {
        "id": "DZ04TRz8ZTfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size=512\n",
        "sample_len=len(X_train)\n",
        "\n",
        "X_train = np.array([X_train*sample_size]).reshape(sample_size,sample_len,len(alphabet))\n",
        "y_train = np.array([y_train*sample_size]).reshape(sample_size,sample_len,len(alphabet))\n",
        "\n",
        "test_len=len(X_test)\n",
        "X_test= np.array([X_test]).reshape(1,test_len,len(alphabet))\n",
        "y_test= np.array([y_test]).reshape(1,test_len,len(alphabet))"
      ],
      "metadata": {
        "id": "K0HP_nNvZQQ-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test), X_test[0:10]"
      ],
      "metadata": {
        "id": "IVBUajsbbats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(input_dim =len(alphabet), units = 100, return_sequences = True))\n",
        "#model.add(LSTM(input_dim =len(alphabet), output_dim = 100, return_sequences = True))\n",
        "\n",
        "# NOTE: TimeDistributed is a special layer for passing weight information through Time - sequence\n",
        "model.add(TimeDistributed(Dense(units = len(alphabet),activation  =  \"sigmoid\")))\n",
        "model.compile(loss=\"binary_crossentropy\",metrics=[\"accuracy\"],optimizer = \"adam\")"
      ],
      "metadata": {
        "id": "OmGC7D0LZJ5I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=1\n",
        "while True:\n",
        "        score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "        print (\"[Iteration %d] score=%f\"%(n,score[1]))\n",
        "        if score[1] == 1.0:\n",
        "            break\n",
        "        n+=1\n",
        "        model.fit(x= X_train, y=y_train, batch_size = 32, epochs = 1, )"
      ],
      "metadata": {
        "id": "-RIYqK66ZJ8L",
        "outputId": "c4bd3624-7e9f-4232-8d8b-93f5f7389485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6784 - accuracy: 0.7843\n",
            "[Iteration 1] score=0.784314\n",
            "16/16 [==============================] - 3s 53ms/step - loss: 0.4399 - accuracy: 0.8873\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1889 - accuracy: 0.9020\n",
            "[Iteration 2] score=0.901961\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.1491 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1288 - accuracy: 0.9020\n",
            "[Iteration 3] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1248 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1214 - accuracy: 0.9020\n",
            "[Iteration 4] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1192 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1168 - accuracy: 0.9020\n",
            "[Iteration 5] score=0.901961\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1150 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1129 - accuracy: 0.9020\n",
            "[Iteration 6] score=0.901961\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.1111 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1088 - accuracy: 0.9020\n",
            "[Iteration 7] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1069 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1067 - accuracy: 0.9020\n",
            "[Iteration 8] score=0.901961\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.1050 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1031 - accuracy: 0.9020\n",
            "[Iteration 9] score=0.901961\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.1013 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0989 - accuracy: 0.9020\n",
            "[Iteration 10] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0963 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0933 - accuracy: 0.9020\n",
            "[Iteration 11] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0930 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0927 - accuracy: 0.9020\n",
            "[Iteration 12] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0909 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0887 - accuracy: 0.9020\n",
            "[Iteration 13] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0863 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0834 - accuracy: 0.9020\n",
            "[Iteration 14] score=0.901961\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0804 - accuracy: 0.9020\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0771 - accuracy: 0.9020\n",
            "[Iteration 15] score=0.901961\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0751 - accuracy: 0.9087\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0756 - accuracy: 0.9118\n",
            "[Iteration 16] score=0.911765\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.0733 - accuracy: 0.9136\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0707 - accuracy: 0.9216\n",
            "[Iteration 17] score=0.921569\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0676 - accuracy: 0.9210\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0651 - accuracy: 0.9216\n",
            "[Iteration 18] score=0.921569\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0644 - accuracy: 0.9259\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0655 - accuracy: 0.9314\n",
            "[Iteration 19] score=0.931373\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.0628 - accuracy: 0.9265\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0594 - accuracy: 0.9314\n",
            "[Iteration 20] score=0.931373\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.0570 - accuracy: 0.9320\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0613 - accuracy: 0.9314\n",
            "[Iteration 21] score=0.931373\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.0527 - accuracy: 0.9369\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0504 - accuracy: 0.9412\n",
            "[Iteration 22] score=0.941176\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.0494 - accuracy: 0.9393\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0469 - accuracy: 0.9412\n",
            "[Iteration 23] score=0.941176\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0479 - accuracy: 0.9400\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0489 - accuracy: 0.9412\n",
            "[Iteration 24] score=0.941176\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0462 - accuracy: 0.9400\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0435 - accuracy: 0.9412\n",
            "[Iteration 25] score=0.941176\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0421 - accuracy: 0.9461\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0399 - accuracy: 0.9510\n",
            "[Iteration 26] score=0.950980\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0402 - accuracy: 0.9504\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0395 - accuracy: 0.9608\n",
            "[Iteration 27] score=0.960784\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0400 - accuracy: 0.9553\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0474 - accuracy: 0.9412\n",
            "[Iteration 28] score=0.941176\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0435 - accuracy: 0.9534\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0436 - accuracy: 0.9412\n",
            "[Iteration 29] score=0.941176\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0379 - accuracy: 0.9638\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0354 - accuracy: 0.9706\n",
            "[Iteration 30] score=0.970588\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.0351 - accuracy: 0.9743\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0353 - accuracy: 0.9804\n",
            "[Iteration 31] score=0.980392\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0328 - accuracy: 0.9804\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0305 - accuracy: 0.9804\n",
            "[Iteration 32] score=0.980392\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0310 - accuracy: 0.9804\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0290 - accuracy: 0.9804\n",
            "[Iteration 33] score=0.980392\n",
            "16/16 [==============================] - 1s 66ms/step - loss: 0.0296 - accuracy: 0.9804\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0282 - accuracy: 0.9804\n",
            "[Iteration 34] score=0.980392\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0294 - accuracy: 0.9810\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0292 - accuracy: 0.9804\n",
            "[Iteration 35] score=0.980392\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0274 - accuracy: 0.9804\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0274 - accuracy: 0.9804\n",
            "[Iteration 36] score=0.980392\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0267 - accuracy: 0.9822\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0249 - accuracy: 0.9804\n",
            "[Iteration 37] score=0.980392\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0252 - accuracy: 0.9810\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0267 - accuracy: 0.9902\n",
            "[Iteration 38] score=0.990196\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0240 - accuracy: 0.9828\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0226 - accuracy: 0.9804\n",
            "[Iteration 39] score=0.980392\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0242 - accuracy: 0.9841\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0230 - accuracy: 0.9804\n",
            "[Iteration 40] score=0.980392\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0225 - accuracy: 0.9859\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "[Iteration 41] score=1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.array([6])\n",
        "enc.inverse_transform(m)"
      ],
      "metadata": {
        "id": "8-Z_PjhBfN9d",
        "outputId": "351a781f-edf7-4de7-ac2d-446a024aea18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['z'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model.predict(X_test)[0]\n",
        "tmpstr = \" \"\n",
        "for p in preds:\n",
        "    m=np.argmax(p).reshape(-1, 1)\n",
        "    m = str(enc.inverse_transform(m,))\n",
        "    tmpstr = tmpstr + m\n",
        "    #print(m)\n",
        "print(tmpstr)"
      ],
      "metadata": {
        "id": "v7VDergIZKBt",
        "outputId": "13d50bde-7aa6-4e02-8447-a019f6f165a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            " ['y']['z']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['x']['y']['z']['q']['r']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['a']['p']['q']['r']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(X_test,y_test,batch_size=32))"
      ],
      "metadata": {
        "id": "LkVyg91LZHtn",
        "outputId": "ad60d323-d5fb-4f32-926a-b134b85a7a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "[0.021867329254746437, 1.0]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT2IM9w8/SGdzeg0kdqnb0"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}